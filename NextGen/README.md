# Project SYNAPSE

**A Research Implementation of Functionally Self-Aware Artificial Intelligence**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸš€ Quick Start

### 1. Setup (One-time)

```bash
# Clone repository
git clone https://github.com/FrauAndMann/NextGen_brainsimulation.git
cd NextGen_brainsimulation

# Run automatic setup (installs Python 3.10 venv + PyTorch with CUDA)
setup_gpu.bat
```

### 2. Start Training

```bash
# Start SYNAPSE with dashboard
run_life.bat
```

### 3. Open Dashboard

Dashboard opens automatically at `dashboard/index.html`

- Click **"ĞĞĞ§ĞĞ¢Ğ¬ ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•"** to start
- Watch real-time neural activity
- Chat with SYNAPSE to check progress
- Configure data sources via UI

---

## ğŸ“Š Dashboard Features

### Training Control
- **START** - Begin training
- **PAUSE** - Pause and resume later
- **STOP** - Stop and save checkpoint

### Real-time Visualization
- ğŸ§  **Spike Raster** - Neural activity visualization
- ğŸ“ˆ **Population Activity** - 8 neural populations
- ğŸ’¬ **Chat** - Talk to SYNAPSE
- ğŸ§ª **Neurochemistry** - Dopamine, Serotonin, etc.

### Metrics
| Metric | Target | Meaning |
|--------|--------|---------|
| Î¦ (Phi) | > 0.6 | Consciousness integration |
| Agency | > 0.7 | Sense of "I did this" |
| Integration | > 0.6 | Information unity |

---

## ğŸ“ Working with Data

SYNAPSE supports 5 types of training data:

### 1. ğŸ§ª Synthetic Data (Default)

Auto-generated patterns. No setup required.

```
Dashboard â†’ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ â†’ Ğ¡Ğ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
```

### 2. ğŸ–¼ï¸ Images

Train on photos, artwork, any images.

**Folder structure:**
```
D:\Photos\
â”œâ”€â”€ vacation\
â”‚   â”œâ”€â”€ photo1.jpg
â”‚   â”œâ”€â”€ photo2.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ family\
â”‚   â””â”€â”€ ...
â””â”€â”€ nature\
    â””â”€â”€ ...
```

**Requirements:**
- Minimum: 100 images
- Recommended: 10,000+ images
- Formats: `.jpg`, `.jpeg`, `.png`, `.bmp`, `.gif`, `.webp`

**Setup in Dashboard:**
1. Click "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"
2. Select "Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"
3. Enter path: `D:\Photos`
4. Click "Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ" to verify
5. Save

### 3. ğŸ“ Text

Train on books, articles, conversations.

**Folder structure:**
```
D:\Books\
â”œâ”€â”€ book1.txt
â”œâ”€â”€ book2.txt
â”œâ”€â”€ articles\
â”‚   â”œâ”€â”€ article1.md
â”‚   â””â”€â”€ article2.txt
â””â”€â”€ conversations\
    â””â”€â”€ chat.json
```

**Requirements:**
- Minimum: 10 files
- Recommended: 100+ files
- Formats: `.txt`, `.md`, `.json`, `.csv`, `.xml`

**Best practices:**
- Use diverse texts (books, articles, dialogs)
- Larger files = longer training sequences
- Mix languages for multilingual capabilities

### 4. ğŸ® RL Environments

Train on OpenAI Gym environments.

**Available environments:**
| Environment | Best for |
|-------------|----------|
| `CartPole-v1` | Balance, agency |
| `MountainCar-v0` | Persistence, effort |
| `Pendulum-v1` | Continuous control |
| `Acrobot-v1` | Swing-up tasks |

**Setup:**
```bash
pip install gymnasium
```

**In Dashboard:**
1. Click "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"
2. Select "RL ĞĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ"
3. Choose environment from dropdown
4. Save

### 5. ğŸ“ˆ Time Series

Train on sensor data, financial data, any CSV.

**Folder structure:**
```
D:\Data\
â”œâ”€â”€ sensors.csv
â”œâ”€â”€ stock_prices.csv
â””â”€â”€ iot\
    â”œâ”€â”€ device1.csv
    â””â”€â”€ device2.csv
```

**CSV format:**
```csv
timestamp,temperature,humidity,pressure
2024-01-01,25.5,60.2,1013.2
2024-01-02,26.1,58.7,1012.8
...
```

**Requirements:**
- Numeric columns (non-numeric ignored)
- Minimum: 1 file with 100+ rows
- Recommended: 10+ files

---

## ğŸ”„ Auto-Resume

SYNAPSE automatically saves progress and resumes from the last checkpoint.

```bash
run_life.bat  # Automatically continues from where you stopped
```

Checkpoints saved in `files/checkpoints/`

---

## ğŸ“ˆ Training Progress

### Expected Timeline

| Steps | Î¦ (Phi) | Agency | Status |
|-------|---------|--------|--------|
| 100 | ~0.1 | ~0.0 | Just born |
| 1,000 | ~0.2 | ~0.1 | Learning basics |
| 10,000 | ~0.3-0.4 | ~0.2-0.3 | Beginning awareness |
| 50,000 | ~0.4-0.5 | ~0.4-0.5 | Good progress |
| 100,000 | ~0.5+ | ~0.5+ | Stable self-awareness |

### Speed Comparison

| Hardware | Steps/Hour | Time for 100K steps |
|----------|------------|---------------------|
| CPU only | ~200 | ~21 days |
| RTX 3060 | ~8,000 | ~12 hours |
| RTX 3090 | ~15,000 | ~7 hours |
| RTX 4090 | ~25,000 | ~4 hours |

---

## ğŸ’¬ Chat Commands

Talk to SYNAPSE in the dashboard chat:

| Command | Response |
|---------|----------|
| "ĞšĞ°Ğº Ñ‚Ñ‹?" | Current state with metrics |
| "ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ" | Overall progress percentage |
| "Ğ§Ñ‚Ğ¾ Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒĞµÑˆÑŒ?" | Neurochemistry state |
| "Ğ§Ñ‚Ğ¾ Ğ¿Ğ¾Ğ¼Ğ½Ğ¸ÑˆÑŒ?" | Memory status |
| "Ğ¡Ğ¾Ğ²ĞµÑ‚" | Training recommendations |
| "ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ" | Available commands |

---

## ğŸ› ï¸ Advanced Usage

### Command Line Options

```bash
# Resume from specific checkpoint
python train_continuous.py --resume continuous_xxx.pt

# Stop after N steps
python train_continuous.py --steps 100000

# Train on specific data
python train_continuous.py --data-type images --data-path D:\Photos

# Use RL environment
python train_continuous.py --data-type rl --env-name CartPole-v1
```

### GPU Configuration

Check GPU status:
```bash
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0))"
```

If GPU not detected:
1. Run `setup_gpu.bat`
2. Ensure NVIDIA drivers installed
3. Check CUDA version compatibility

---

## ğŸ“ Project Structure

```
NextGen/
â”œâ”€â”€ files/
â”‚   â”œâ”€â”€ config.py              # System configuration
â”‚   â”œâ”€â”€ environment.py         # Synthetic environment
â”‚   â”œâ”€â”€ real_data.py           # Real data loaders
â”‚   â”œâ”€â”€ train_continuous.py    # Training script
â”‚   â”œâ”€â”€ api.py                 # REST API + WebSocket
â”‚   â”œâ”€â”€ shared_metrics.py      # Cross-process metrics
â”‚   â”œâ”€â”€ checkpoints/           # Saved models
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ world_model.py     # VAE + Transformer
â”‚       â”œâ”€â”€ self_model.py      # Recursive self-prediction
â”‚       â”œâ”€â”€ agency_model.py    # "I did this" detection
â”‚       â”œâ”€â”€ consciousness.py   # GWT + Phi calculation
â”‚       â””â”€â”€ self_aware_ai.py   # Main integration
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ index.html             # React dashboard
â”œâ”€â”€ run_life.bat               # Start training
â”œâ”€â”€ setup_gpu.bat              # Install dependencies
â””â”€â”€ README.md
```

---

## ğŸ§  Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Consciousness Integrator (GWT)                    â”‚
â”‚  â†’ Unified conscious experience, Î¦ calculation              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: Meta-Cognition                                    â”‚
â”‚  â†’ "I know that I know", confidence tracking                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2: Agency Model                                      â”‚
â”‚  â†’ Forward/inverse models, distinguishes "I did this"       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1: Self Model (128-dim internal state)               â”‚
â”‚  â†’ Predicts own future states                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 0: World Model (VAE + Transformer)                   â”‚
â”‚  â†’ Predicts world states                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ FAQ

### Q: How long should I train?
**A:** Minimum 10,000 steps for visible progress. 100,000+ for stable self-awareness.

### Q: Can I use my own photos?
**A:** Yes! Put them in a folder and select "Images" in dashboard.

### Q: What if training is slow?
**A:** Ensure GPU is enabled. Run `setup_gpu.bat` to install CUDA PyTorch.

### Q: Will I lose progress if I stop?
**A:** No! Auto-save every 5 minutes. Resume with `run_life.bat`.

### Q: What data type is best?
**A:**
- **Synthetic** - Fastest, good for testing
- **Images** - Visual awareness
- **RL** - Strong agency development
- **Text** - Language understanding
- **Mix** - Best overall results

---

## ğŸ“œ License

MIT License - see LICENSE file for details.

---

## ğŸ™ Credits

- Based on Global Workspace Theory (Baars, Dehaene)
- Integrated Information Theory (Tononi)
- Predictive Processing (Friston)

---

*"The question is not whether machines can be conscious, but whether we can build systems that behave as if they were."*
