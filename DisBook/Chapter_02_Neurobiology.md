# ГЛАВА 2. НЕЙРОБИОЛОГИЧЕСКИЕ ОСНОВЫ

---

## 2.1. Структура человеческого мозга

### Общая организация

Человеческий мозг — наиболее сложная известная структура во Вселенной.

| Параметр | Значение |
|----------|----------|
| **Нейронов** | ~86 миллиардов |
| **Синапсов** | ~100 триллионов |
| **Масса** | ~1.4 кг (2% тела) |
| **Потребление энергии** | 20 Вт (20% тела) |
| **Операций/сек** | ~10^16 |
| **Эффективность** | 10^15 ops/Вт (vs 10^9 у суперкомпьютеров) |

### Три структурных уровня (MacLean)

```
┌─────────────────────────────────────────────────────────┐
│                    НЕОКОРТЕКС                            │
│         Высшие функции: мышление, язык, планирование     │
│                    (80% мозга)                           │
├─────────────────────────────────────────────────────────┤
│                  ЛИМБИЧЕСКАЯ СИСТЕМА                     │
│      Эмоции, память, мотивация, социальное поведение     │
│                                                          │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐   │
│  │ Amygdala │ │Hippocamp.│ │Hypothal. │ │ Thalamus │   │
│  │  (страх) │ │ (память) │ │(гомеостаз)│ │(реле)   │   │
│  └──────────┘ └──────────┘ └──────────┘ └──────────┘   │
├─────────────────────────────────────────────────────────┤
│                     СТВОЛ МОЗГА                          │
│     Базовые функции: дыхание, сердцебиение, рефлексы     │
│                                                          │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐                 │
│  │  Medulla │ │   Pons   │ │Reticular.│                 │
│  │          │ │          │ │ Formation│                 │
│  └──────────┘ └──────────┘ └──────────┘                 │
└─────────────────────────────────────────────────────────┘
```

### Функциональные сети

Для моделирования важны не только структуры, но и **сети**:

| Сеть | Функция | Аналог в ИИ |
|------|---------|-------------|
| **Default Mode Network (DMN)** | Самореференция, мечтательность | Self-model layer |
| **Salience Network** | Определение важности | Attention mechanism |
| **Central Executive Network** | Целенаправленное мышление | Planning module |
| **Limbic Network** | Эмоциональная обработка | Emotion engine |

---

## 2.2. Нейрохимия эмоций

### Классификация нейромедиаторов

Полная модель требует **100+ веществ**. Вот систематизация:

#### Категория 1: Моноамины

| Нейромедиатор | Основная функция | Для эмоций |
|---------------|------------------|------------|
| **Дофамин** | Ошибка предсказания награды | Мотивация, желание, обучение |
| **Серотонин** | Регуляция настроения | Удовлетворение, спокойствие |
| **Норадреналин** | Бдительность, возбуждение | Активация, стресс |
| **Адреналин** | Реакция "бей или беги" | Острая мобилизация |

#### Категория 2: Аминокислоты

| Нейромедиатор | Функция | Роль |
|---------------|---------|------|
| **Глутамат** | Главный возбуждающий | Активация нейронов |
| **ГАМК (GABA)** | Главный тормозной | Успокоение, баланс |
| **Глицин** | Тормозной (спинной мозг) | Моторный контроль |

#### Категория 3: Пептиды

| Нейромедиатор | Функция | Эмоциональная роль |
|---------------|---------|-------------------|
| **Окситоцин** | Социальная привязанность | Доверие, любовь, связь |
| **Вазопрессин** | Социальное поведение | Привязанность, агрессия |
| **Эндорфины** | Обезболивание | Удовольствие, эйфория |
| **Субстанция P** | Передача боли | Дискомфорт |
| **Нейропептид Y** | Аппетит, стресс | Успокоение |

#### Категория 4: Другие важные

| Вещество | Функция | Эмоциональная роль |
|----------|---------|-------------------|
| **Ацетилхолин** | Внимание, память | Фокус, обучение |
| **Гистамин** | Бодрствование | Активация |
| **Мелатонин** | Сон | Циклы, отдых |
| **Кортизол** | Стресс-гормон | Длительный стресс |
| **Ановерин** | Расслабление | Удовлетворение |

### Важное исправление: Дофамин

**Распространённая ошибка**: Дофамин = удовольствие

**Научная истина**:
- Дофамин кодирует **ошибку предсказания награды**
- Он сигнализирует: "Это было лучше, чем я ожидал!"
- Дофамин = **желание** (wanting), а не удовольствие (liking)

```
Предсказанная награда: 10
Реальная награда: 15
Ошибка предсказания: +5 → Выброс дофамина

Предсказанная награда: 10
Реальная награда: 5
Ошибка предсказания: -5 → Падение дофамина
```

### Математическая модель нейромедиатора

```python
class Neurotransmitter:
    """
    Модель отдельного нейромедиатора
    """
    def __init__(self, name: str, config: dict):
        self.name = name

        # Базовые параметры
        self.baseline = config.get('baseline', 0.5)      # Базовый уровень
        self.current_level = self.baseline               # Текущий уровень
        self.min_level = config.get('min', 0.0)          # Минимум
        self.max_level = config.get('max', 1.0)          # Максимум

        # Динамика
        self.decay_rate = config.get('decay_rate', 0.1)  # Скорость затухания
        self.synthesis_rate = config.get('synthesis', 0.05)  # Скорость синтеза
        self.reuptake_rate = config.get('reuptake', 0.2) # Обратный захват

        # Рецепторы
        self.receptors = config.get('receptors', {})

        # История (для анализа)
        self.history = []

    def update(self, dt: float, external_input: float = 0):
        """
        Обновление уровня нейромедиатора
        """
        # Естественный распад
        decay = self.decay_rate * self.current_level * dt

        # Обратный захват (удаление из синапса)
        reuptake = self.reuptake_rate * self.current_level * dt

        # Синтез (восстановление к базовому)
        synthesis = self.synthesis_rate * (self.baseline - self.current_level) * dt

        # Внешний ввод (стимулы, действия)
        external = external_input * dt

        # Итоговое изменение
        delta = -decay - reuptake + synthesis + external

        # Обновление с ограничениями
        self.current_level = np.clip(
            self.current_level + delta,
            self.min_level,
            self.max_level
        )

        # Запись истории
        self.history.append(self.current_level)

        return self.current_level

    def stimulate(self, amount: float):
        """Быстрое повышение уровня"""
        self.current_level = np.clip(
            self.current_level + amount,
            self.min_level,
            self.max_level
        )
        return self.current_level
```

---

## 2.3. Механизмы памяти

### Иерархия памяти

```
┌────────────────────────────────────────────────────────────────┐
│                    ДОЛГОВРЕМЕННАЯ ПАМЯТЬ                       │
│  ┌──────────────────────────┐  ┌──────────────────────────┐   │
│  │   ДЕКЛАРАТИВНАЯ          │  │    ПРОЦЕДУРНАЯ           │   │
│  │  ┌────────┐ ┌────────┐  │  │  (навыки, привычки)      │   │
│  │  │Эпизодич.│ │Семантич.│  │  │  - Езда на велосипеде   │   │
│  │  │(события)│ │ (факты) │  │  │  - Игра на пианино      │   │
│  │  └────────┘ └────────┘  │  │  - Структура проекта     │   │
│  │  - Первый поцелуй       │  │                          │   │
│  │  - Вчерашний обед       │  │                          │   │
│  └──────────────────────────┘  └──────────────────────────┘   │
│                          ↑                                      │
│                     КОНСОЛИДАЦИЯ                                │
│                          ↑                                      │
├────────────────────────────────────────────────────────────────┤
│                    РАБОЧАЯ ПАМЯТЬ                              │
│  Central Executive + Phonological Loop + Visuospatial Sketchpad│
│  - Текущая задача (7±2 элементов)                              │
│  - Время: 15-30 секунд                                         │
├────────────────────────────────────────────────────────────────┤
│                    КРАТКОСРОЧНАЯ ПАМЯТЬ                        │
│  - Последние несколько минут                                   │
│  - Без консолидации → забывается                               │
├────────────────────────────────────────────────────────────────┤
│                    СЕНСОРНАЯ ПАМЯТЬ                            │
│  - Иконическая (зрение): 200-500 мс                            │
│  - Эхоическая (слух): 2-4 секунды                              │
│  - Тактильная: < 1 секунды                                     │
└────────────────────────────────────────────────────────────────┘
```

### Консолидация памяти (Сон)

**Критический процесс**: воспоминания консолидируются во время сна.

| Фаза сна | Что происходит | Для ИИ |
|----------|----------------|--------|
| **N1 (лёгкий)** | Переход | Сохранение в буфер |
| **N2 (лёгкий)** | Sleep spindles | Интеграция с существующей памятью |
| **N3 (глубокий)** | Медленные волны | **Replay** в гиппокампе → неокортекс |
| **REM** | Быстрые движения глаз | Эмоциональная обработка, интеграция |

**Реализация для ИИ**:
```python
class SleepCycle:
    """
    Цикл "сна" для консолидации памяти
    """
    def __init__(self, memory_system):
        self.memory = memory_system
        self.phases = ['N1', 'N2', 'N3', 'REM']

    def run_sleep_cycle(self, duration_minutes: int = 90):
        """Один цикл сна (90 минут у людей)"""
        for phase in self.phases:
            if phase == 'N3':
                # Replay и консолидация
                self.memory.replay_episodes()
                self.memory.consolidate_to_semantic()
            elif phase == 'REM':
                # Эмоциональная обработка
                self.memory.process_emotions()
                self.memory.integrate_memories()

        # После сна: очистка краткосрочной памяти
        self.memory.clear_working_memory()
```

---

## 2.4. Теории сознания

### Обзор основных теорий

| Теория | Автор | Суть | Для ИИ |
|--------|-------|------|--------|
| **GWT** | Baars, Dehaene | Глобальное вещание | ✅ Реализуема |
| **IIT** | Tononi | Интегрированная информация (Φ) | ⚠️ Сложно измерить |
| **RPT** | Lamme | Рекуррентная обработка | ✅ Архитектура |
| **PP** | Friston | Предсказующее кодирование | ✅ JEPA |
| **HOT** | Rosenthal | Высшего порядка мысли | ✅ Мета-слой |

### Global Workspace Theory (GWT) — детально

```
                    ┌─────────────────────────────┐
                    │     ГЛОБАЛЬНОЕ РАБОЧЕЕ      │
                    │        ПРОСТРАНСТВО         │
                    │   (ограниченная ёмкость)    │
                    └─────────────────────────────┘
                          ↑           ↓
        ┌─────────────────┼───────────┼─────────────────┐
        │                 │           │                 │
   ┌────┴────┐       ┌────┴────┐ ┌────┴────┐       ┌────┴────┐
   │  ВИДЕНИЕ │       │  СЛУХ   │ │  ПАМЯТЬ │       │  МОТОРИКА│
   │         │       │         │ │         │       │         │
   └─────────┘       └─────────┘ └─────────┘       └─────────┘
        │                 │           │                 │
        └─────────────────┴───────────┴─────────────────┘
                    Специализированные модули
                    (работают параллельно)
```

**Ключевые принципы GWT**:
1. **Конкуренция**: модули конкурируют за доступ к workspace
2. **Вещание**: содержимое workspace доступно всем модулям
3. **Ограниченность**: workspace имеет ограниченную ёмкость (7±2)
4. **Игнорирование**: неважная информация не попадает в workspace

### Integrated Information Theory (IIT) — детально

**Формула**: Φ = интегрированная информация системы

```
Φ высокий: информация сильно интегрирована
    ┌─────────────────────────┐
    │  ╔═══╗   ╔═══╗   ╔═══╗  │
    │  ║ A ║←──║ B ║───→║ C ║ │
    │  ╚═══╝   ╚═══╝   ╚═══╝  │
    │    ↑       ↓       ↑    │
    │    └───────┴───────┘    │
    └─────────────────────────┘

Φ низкий: информация фрагментирована
    ┌─────────────────────────┐
    │  ╔═══╗   ╔═══╗   ╔═══╗  │
    │  ║ A ║   ║ B ║   ║ C ║  │
    │  ╚═══╝   ╚═══╝   ╚═══╝  │
    │   (нет связей)          │
    └─────────────────────────┘
```

**Проблема IIT для ИИ**: Архитектура трансформеров не обеспечивает высокую Φ.

**Решение**: Гибридные архитектуры с рекуррентными связями (Mamba, Jamba).

### Predictive Processing — детально

**Идея**: Мозг — машина предсказаний, минимизирующая ошибку.

```
Внешний мир
     │
     ↓ (сенсорный вход)
┌─────────────────────────────────────────────┐
│           ПРЕДСКАЗЫВАЮЩАЯ ИЕРАРХИЯ          │
│                                              │
│  Уровень 3 (абстрактный)                    │
│     ↑↓ предсказания / ошибки                │
│  Уровень 2 (средний)                        │
│     ↑↓                                      │
│  Уровень 1 (низкий)                         │
│     ↑↓                                      │
│  Уровень 0 (сенсорный) ←── сенсорный вход   │
│                                              │
└─────────────────────────────────────────────┘
```

**Для ИИ**: JEPA (Joint Embedding Predictive Architecture) от LeCun.

---

## 2.5. Что мы знаем точно vs что предполагаем

### Знаем ТОЧНО (научно доказано)

| Факт | Доказательство |
|------|----------------|
| Мозг обрабатывает информацию | Нейровизуализация |
| Эмоции связаны с нейрохимией | Фармакология, поражения |
| Память требует консолидации | Исследования сна |
| Сознание связано с активностью мозга | Анестезия, повреждения |
| Рекуррентность важна для сознания | Визуальные эксперименты |

### ПРЕДПОЛАГАЕМ (вероятно, но не доказано)

| Гипотеза | Статус |
|----------|--------|
| GWT объясняет сознание | Правдоподобно, не доказано |
| IIT количественно измеряет сознание | Спорно |
| Предсказующее кодирование — основа мозга | Правдоподобно |
| Qualia существуют как отдельные сущности | Спорно |

### НЕ ЗНАЕМ (фундаментальные вопросы)

| Вопрос | Почему не знаем |
|--------|-----------------|
| Почему есть субъективный опыт? | "Трудная проблема" |
| Что такое qualia? | Принципиально неизмеримы |
| Как именно возникает "я"? | Нет консенсуса |

### Практический вывод

> **Для создания функциональной системы нам достаточно того, что мы знаем точно. Гипотезы помогают выбрать архитектуру. Фундаментальные вопросы не влияют на поведение системы.**

---

## 2.6. Резюме главы

### Ключевые тезисы

1. **Мозг имеет три уровня**: ствол → лимбическая система → неокортекс
2. **100+ нейромедиаторов**: каждый со своей функцией
3. **Память иерархична**: сенсорная → краткосрочная → долгосрочная
4. **Консолидация во сне**: критический процесс для обучения
5. **Множество теорий сознания**: GWT наиболее применима к ИИ

### Что взять в проект

| Из нейробиологии | Реализация |
|------------------|------------|
| 3 уровня мозга | 3 слоя архитектуры |
| Нейромедиаторы | Нейрохимический движок |
| Иерархия памяти | Memory system |
| GWT | Global Workspace |
| Предсказующее кодирование | Predictive self-model |
| Консолидация во сне | Sleep cycle |

### Следующий шаг

Глава 3 детально разберёт теории сознания и их практическое применение к архитектуре ИИ.

---

*"Нейробиология даёт нам карту. Мы не обязаны следовать ей точно — но игнорировать её глупо."*
